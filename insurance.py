# -*- coding: utf-8 -*-
"""Insurance.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11pc3WJlPG7SVZjgFKZqWtFjFQVZl7Ypt
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
sns.set_style('whitegrid')
import warnings
warnings.filterwarnings('ignore')

"""# Step 1: Load the data"""

file_path = '/content/TravelInsurancePrediction_Dataset.csv'
data = pd.read_csv(file_path)

"""# Step 2: Understand the data"""

data.info()

print(data.head())

data_shape = data.shape
print("Data Shape:", data_shape)

# Convert all float columns to integer
float_columns = data.select_dtypes(include=['float64']).columns
data[float_columns] = data[float_columns].astype(int)

# Check the data types of the columns after conversion
print("\nData types after converting all float columns to integers:")
print(data.dtypes)

data_types = data.dtypes
print("\nData Types:\n", data.dtypes)

missing_values = data.isnull().sum()
print("\nMissing Values:\n", data.isnull().sum())

data_summary = data.describe()
print("\nData Summary:\n", data.describe())

# Check Numerical dataframe statistics
data.describe(include = np.number).T

# Check Object-type datafram statistics
data.describe(include = 'object').T

data_head = data.head()
print("\nFirst 5 Rows of Data:\n", data.head())

"""# Step 3: Data Cleaning"""

# Check for duplicates
print("\nDuplicate Rows:", data.duplicated().sum())

"""#Remove Repeated values"""

# Drop duplicates if any
data = data.drop_duplicates()

data_shape = data.shape
print("Data Shape:", data_shape)

"""#Separate X & Y"""

X = data.drop('TravelInsurance', axis=1)
Y = data['TravelInsurance']

X.shape,Y.shape



"""#Train Test Split"""

from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=7,stratify=Y)

X_train.shape, X_test.shape, Y_train.shape, Y_test.shape

"""#Check Columns with single Value"""

data.nunique()

"""#One hot encoding"""

X_train.dtypes

X_train_ohe = pd.get_dummies(X_train)
X_train.shape, X_train_ohe.shape

X_train_ohe.columns

X_train_ohe.head()

X_test_ohe = pd.get_dummies(X_test)
X_test.shape, X_test_ohe.shape



"""# Step 4: Univariate Analysis"""

# Distribution of numerical features
num_features = data.select_dtypes(include=[np.number]).columns
for feature in num_features:
    plt.figure(figsize=(10, 5))
    sns.histplot(data[feature], kde=True)
    plt.title(f'Distribution of {feature}')
    plt.show()

"""# Distribution of categorical features"""

cat_features = data.select_dtypes(include=[object]).columns
for feature in cat_features:
    plt.figure(figsize=(10, 5))
    sns.countplot(y=data[feature])
    plt.title(f'Count of {feature}')
    plt.show()

"""# Function to detect outliers using IQR"""

def detect_outliers_iqr(df, column):
    Q1 = df[column].quantile(0.25)
    Q3 = df[column].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    return df[(df[column] < lower_bound) | (df[column] > upper_bound)]

"""# Detecting outliers in numerical features"""

num_features = data.select_dtypes(include=[np.number]).columns
for feature in num_features:
    outliers = detect_outliers_iqr(data, feature)
    print(f'Outliers detected in {feature}: {len(outliers)}')

# Visualize outliers using Box plot
plt.figure(figsize=(10, 5))
sns.boxplot(x=data[feature])
plt.title(f'Box plot of {feature}')
plt.show()



def cap_outliers(df, column):
    Q1 = df[column].quantile(0.25)
    Q3 = df[column].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    df[column] = np.where(df[column] < lower_bound, lower_bound, df[column])
    df[column] = np.where(df[column] > upper_bound, upper_bound, df[column])
    return df

for feature in num_features:
    data = cap_outliers(data, feature)
    # Check the box plot after capping
    plt.figure(figsize=(10, 5))
    sns.boxplot(data[feature])
    plt.title(f'Box plot of {feature} after capping')
    plt.show()

# Calculate the z-scores for each numerical column
z_scores = np.abs((data.select_dtypes(include=np.number)) - data.select_dtypes(include=np.number).mean()) / data.select_dtypes(include=np.number).std()

# Identify any values with z-score greater than 3
potential_outliers = data[(z_scores > 3).any(axis=1)]

# Print the potential outliers
print(potential_outliers)

# Create scatter plots for pairs of numerical features
for i in range(len(num_features)):
    for j in range(i + 1, len(num_features)):
        plt.figure(figsize=(10, 5))
        sns.scatterplot(x=data[num_features[i]], y=data[num_features[j]])
        plt.title(f'Scatter plot of {num_features[i]} vs {num_features[j]}')
        plt.xlabel(num_features[i])
        plt.ylabel(num_features[j])
        plt.show()

# Visualize the distribution of the target variable

sns.countplot(data=data,x='TravelInsurance',palette="Blues")
plt.show()
data.groupby('TravelInsurance').agg({'TravelInsurance':'count'})

# Visualize by travel insurance and count number of customers

labels = ['Not Purchased', 'Purchased']
values = data['TravelInsurance'].value_counts()

fig = px.pie( names=labels, values=values, color_discrete_sequence=['lightblue', 'lightpink'],
             title='How many people have purchased the insurance?', template='plotly_white')

fig.show()





"""#Classifications"""

from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier

lr = LogisticRegression(class_weight='balanced',random_state = 7,solver = 'saga')
lr.fit(X_train_ohe,Y_train)
lr.coef_

Y_pred = lr.predict(X_test_ohe)
Y_test.shape,Y_pred.shape
from sklearn.metrics import classification_report
print(classification_report(Y_test,Y_pred))

from sklearn.model_selection import GridSearchCV
# Define the hyperparameter grid to search over
lr_params = {
    'penalty': ['l1', 'l2'],
    'C': [1, 10, 100]
}

# Perform grid search cross-validation to find the best hyperparameters
grid_lr = GridSearchCV(lr, lr_params, cv=2, verbose = 2)
grid_lr.fit(X_train_ohe,Y_train)
lr_best = grid_lr.best_estimator_

# Print the best hyperparameters and score found during the grid search
print("Best parameters:", lr_best)
print("Best Accuracy Score: {:.2f}%".format(grid_lr.best_score_ * 100))

svc1 = SVC(class_weight='balanced', random_state=7)
svc1.fit(X_train_ohe, Y_train)
Y_pred_svc = svc1.predict(X_test_ohe)
print("SVC Classification Report:\n",classification_report(Y_test,Y_pred_svc))

gnb =GaussianNB()
gnb.fit(X_train_ohe,Y_train)
Y_pred_gnb = gnb.predict(X_test_ohe)
print("GaussianNB Classification Report:\n",classification_report(Y_test,Y_pred_gnb))

mnb = MultinomialNB()
mnb.fit(X_train_ohe,Y_train)
Y_pred_mnb = mnb.predict(X_test_ohe)
print("MultinomialNB Classification Report:\n",classification_report(Y_test,Y_pred_mnb))

bnb = BernoulliNB()
bnb.fit(X_train_ohe,Y_train)
Y_pred_bnb = bnb.predict(X_test_ohe)
print("BernoulliNB Classification Report:\n",classification_report(Y_test,Y_pred_bnb))

knn = KNeighborsClassifier()
knn.fit(X_train_ohe,Y_train)
Y_pred_knn = knn.predict(X_test_ohe)
print("KNeighborsClassifier Classification Report:\n",classification_report(Y_test,Y_pred_knn))

# Define the hyperparameter grid to search over
knn_params = {'n_neighbors': range(1, 31)}

# Perform grid search cross-validation to find the best hyperparameters
grid_knn = GridSearchCV(knn, knn_params, cv=2)
grid_knn.fit(X_train_ohe, Y_train)
knn_best = grid_knn.best_estimator_

# Print the best hyperparameters and score found during the grid search
print("Best parameters:", knn_best)
print("Best Accuracy Score: {:.2f}%".format(grid_knn.best_score_ * 100))

rfc = RandomForestClassifier(max_samples= 0.8,oob_score = True,random_state=7)
rfc.fit(X_train_ohe,Y_train)
Y_pred_rfc = rfc.predict(X_test_ohe)
print("RandomForestClassifier Classification Report:\n",classification_report(Y_test,Y_pred_rfc))

# Define the hyperparameter grid to search over
rfc_params = {
    'n_estimators': [50, 200],
    'min_samples_split': [0.6,0.8]
}

# Perform grid search cross-validation to find the best hyperparameters
grid_rfc = GridSearchCV(rfc, rfc_params, cv=2)
grid_rfc.fit(X_train_ohe,Y_train)
rfc_best = grid_rfc.best_estimator_

# Print the best hyperparameters and score found during the grid search
print("Best parameters:", rfc_best)
print("Best Accuracy Score: {:.2f}%".format(grid_rfc.best_score_ * 100))

dtc = DecisionTreeClassifier(criterion='gini', random_state=7,class_weight= 'balanced')
dtc.fit(X_train_ohe,Y_train)
Y_pred_dtc = dtc.predict(X_test_ohe)
print("DecisionTreeClassifier Classification Report:\n",classification_report(Y_test,Y_pred_dtc))

# Define the hyperparameter grid to search over
dtc_params = {
    'criterion': ['gini', 'entropy'],
    'max_depth': [2, 4, 6, 8, 10],
    'min_samples_split': [2, 4, 6, 8],
    'min_samples_leaf': [1, 2, 3, 4]
}

# Perform grid search cross-validation to find the best hyperparameters
grid_dtc = GridSearchCV(dtc, dtc_params, cv=2)
grid_dtc.fit(X_train_ohe,Y_train)
dt_best = grid_dtc.best_estimator_

# Print the best hyperparameters and score found during the grid search
print("Best parameters:", dt_best)
print("Best Accuracy Score: {:.2f}%".format(grid_dtc.best_score_ * 100))

